# -*- coding: utf-8 -*-
"""wikipedia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lp8Z45phO9jqTr0TFrzhoidiNq4ZbWj3
"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive

!ls /content/drive/MyDrive/InfosysVirtual

epson_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia/EpsonV550/150"

import os

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
scanner_counts = {}

for scanner in os.listdir(base_path):
    scanner_path = os.path.join(base_path, scanner)
    if os.path.isdir(scanner_path):
        count = sum(fname.lower().endswith('.tif') for fname in os.listdir(scanner_path))
        scanner_counts[scanner] = count

for scanner, count in scanner_counts.items():
    print(f"{scanner}: {count} .tif files")

import os
import cv2
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
scanner_summary = {}

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        dpi_summary[dpi] = len(tif_files)

        # Convert and preview first 2 grayscale images
        for fname in tif_files[:2]:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                plt.figure(figsize=(4, 4))
                plt.title(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
                plt.imshow(img, cmap='gray')
                plt.axis('off')
                plt.show()
            else:
                print(f"‚ö†Ô∏è Could not read: {img_path}")

    scanner_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Grayscale Conversion Summary (Preview Only):")
for scanner, dpi_data in scanner_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} files converted")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
preprocess_summary = {}

def preprocess_image(img):
    # Resize to standard size (optional)
    img_resized = cv2.resize(img, (512, 512))

    # Histogram equalization
    img_eq = cv2.equalizeHist(img_resized)

    return img_eq

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_pre = preprocess_image(img)

            # Show original vs preprocessed
            fig, axs = plt.subplots(1, 2, figsize=(8, 4))
            axs[0].imshow(img, cmap='gray')
            axs[0].set_title("Original")
            axs[0].axis('off')

            axs[1].imshow(img_pre, cmap='gray')
            axs[1].set_title("Preprocessed")
            axs[1].axis('off')

            plt.suptitle(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Preprocessing Summary (Preview Only):")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} images preprocessed")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
preprocess_summary = {}

def preprocess_image(img):
    # Resize to standard size
    img_resized = cv2.resize(img, (512, 512))

    # Denoise using Gaussian blur
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)

    # Normalize to [0, 1] float
    img_normalized = img_denoised.astype(np.float32) / 255.0

    return img_resized, img_denoised, img_normalized

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_resized, img_denoised, img_normalized = preprocess_image(img)

            # Show original, denoised, normalized
            fig, axs = plt.subplots(1, 3, figsize=(12, 4))
            axs[0].imshow(img_resized, cmap='gray')
            axs[0].set_title("Resized")
            axs[0].axis('off')

            axs[1].imshow(img_denoised, cmap='gray')
            axs[1].set_title("Denoised")
            axs[1].axis('off')

            axs[2].imshow(img_normalized, cmap='gray')
            axs[2].set_title("Normalized")
            axs[2].axis('off')

            plt.suptitle(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Preprocessing Summary (Denoise + Normalize):")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Define base path
wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
feature_summary = {}

# üßº Preprocessing + Feature Extraction
def extract_features(img_gray):
    img_resized = cv2.resize(img_gray, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0

    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])
    high_pass = cv2.filter2D(img_normalized, -1, kernel)

    coeffs2 = pywt.dwt2(img_normalized, 'db1')
    approx, (horiz, vert, diag) = coeffs2

    return high_pass, approx, horiz, vert, diag

# üîÅ Traverse folders
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for i, fname in enumerate(tif_files):
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            hp, approx, horiz, vert, diag = extract_features(img_gray)
            valid_count += 1

            if i == 0:
                titles = ["High-Pass", "Approximation", "Horizontal", "Vertical", "Diagonal"]
                images = [hp, approx, horiz, vert, diag]
                fig, axs = plt.subplots(1, 5, figsize=(20, 4))
                for j in range(5):
                    axs[j].imshow(images[j], cmap='gray')
                    axs[j].set_title(titles[j])
                    axs[j].axis('off')
                plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
                plt.tight_layout()
                plt.show()

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary for Wikipedia:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Base path
wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
feature_summary = {}

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üîÅ Traverse folders
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)

            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            fig, axs = plt.subplots(1, 3, figsize=(15, 4))
            axs[0].imshow(img_pre, cmap='gray')
            axs[0].set_title("Preprocessed")

            axs[1].imshow(fft_img, cmap='gray')
            axs[1].set_title("FFT Spectrum")

            axs[2].imshow(prnu_img, cmap='gray')
            axs[2].set_title("PRNU Residual")

            plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary for Wikipedia:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import matplotlib.pyplot as plt

wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
histograms = []

# Collect histograms
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        if not tif_files:
            continue

        # Use first valid image
        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_resized = cv2.resize(img_gray, (512, 512))
            hist = cv2.calcHist([img_resized], [0], None, [256], [0, 256])
            label = f"{scanner} ‚Üí {dpi}"
            histograms.append((label, hist))
            break  # Only one image per DPI

# Plot histograms
for label, hist in histograms:
    plt.figure(figsize=(6, 3))
    plt.plot(hist, color='gray')
    plt.title(f"Histogram: {label}", fontsize=10)
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()

image_counts = {}

for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        dpi_summary[dpi] = len(tif_files)

    image_counts[scanner] = dpi_summary

# Flatten for bar graph
labels = []
counts = []

for scanner, dpi_data in image_counts.items():
    for dpi, count in dpi_data.items():
        labels.append(f"{scanner}\n{dpi}")
        counts.append(count)

plt.figure(figsize=(12, 6))
plt.bar(labels, counts, color='skyblue')
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Images")
plt.title("üìä Image Count per Scanner/DPI Folder (Wikipedia)")
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt
from PIL import Image

# üìÅ Input and output paths
input_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
output_base = "/content/drive/MyDrive/InfosysVirtual/Wikipedia_Features"

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üì¶ Save image as PNG
def save_image(array, path):
    array = np.clip(array * 255, 0, 255).astype(np.uint8)
    Image.fromarray(array).save(path)

# üîÅ Traverse folders
for scanner in sorted(os.listdir(input_path)):
    scanner_path = os.path.join(input_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # üìÅ Create output folder
            save_folder = os.path.join(output_base, scanner, dpi)
            os.makedirs(save_folder, exist_ok=True)

            # üßæ Save images
            base_name = os.path.splitext(fname)[0]
            save_image(img_pre, os.path.join(save_folder, f"{base_name}_preprocessed.png"))
            save_image(fft_img / np.max(fft_img), os.path.join(save_folder, f"{base_name}_fft.png"))
            save_image(prnu_img / np.max(np.abs(prnu_img)), os.path.join(save_folder, f"{base_name}_prnu.png"))

            print(f"‚úÖ Saved: {scanner}/{dpi}/{fname}")