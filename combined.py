# -*- coding: utf-8 -*-
"""Combined.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15JvYsfO9u1L83yhRV79FUXbfq_kgZTix
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import matplotlib.pyplot as plt

# Define the base path to your project folder
base_path = '/content/drive/MyDrive/InfosysVirtual'

# List all items in the base path
folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]

print("Folders inside 'InfosysVirtual':")
for folder in folders:
    print("-", folder)

# Define the base path
base_path = '/content/drive/MyDrive/InfosysVirtual'

# Get all main folders
main_folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]

print(f"Total main folders in 'InfosysVirtual': {len(main_folders)}\n")

# Loop through each main folder and list its subfolders
for main in main_folders:
    main_path = os.path.join(base_path, main)
    subfolders = [sf for sf in os.listdir(main_path) if os.path.isdir(os.path.join(main_path, sf))]

    print(f"üìÅ {main} ({len(subfolders)} subfolders)")
    for idx, sub in enumerate(subfolders, start=1):
        print(f"   {idx}. {sub}")
    print("-" * 40)

import os

# Define base path
base_path = '/content/drive/MyDrive/InfosysVirtual'

# Walk through all folders recursively
print("üìÅ Full File Inventory (Recursive):\n")

for root, dirs, files in os.walk(base_path):
    # Skip empty folders
    if files:
        relative_path = os.path.relpath(root, base_path)
        print(f"üìÇ Folder: {relative_path} ‚Üí {len(files)} files")

        # Show filenames (limit to first 5 for readability)
        for idx, file in enumerate(files[:5], start=1):
            print(f"   {idx}) {file}")

        if len(files) > 5:
            print(f"   ...and {len(files) - 5} more files")

        print("-" * 40)

import os
import pandas as pd
from PIL import Image

# Path to Flatfield folder
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"

# Collect metadata
metadata = []

for scanner_model in sorted(os.listdir(flatfield_path)):
    scanner_folder = os.path.join(flatfield_path, scanner_model)
    if not os.path.isdir(scanner_folder):
        continue

    for file_name in sorted(os.listdir(scanner_folder)):
        file_path = os.path.join(scanner_folder, file_name)
        if not os.path.isfile(file_path):
            continue

        info = {
            "file_name": file_name,
            "format": None,
            "size": None,
            "mode": None,
            "scanner_model": scanner_model,
            "folder": "Flatfield",
            "path": file_path
        }

        try:
            with Image.open(file_path) as img:
                info["format"] = img.format
                info["size"] = img.size
                info["mode"] = img.mode
        except:
            info["format"] = "Unreadable"

        metadata.append(info)

# Create DataFrame
df_flatfield = pd.DataFrame(metadata)

# Show all rows and columns like your notebook
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

# Display summary
print(f"‚úÖ Total files scanned: {len(df_flatfield)}")
print(f"‚ùå Unreadable files: {df_flatfield[df_flatfield['format'] == 'Unreadable'].shape[0]}")

# Show full table
df_flatfield

import os
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

# Path to Flatfield folder
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"

# Initialize metadata list
metadata = []

# Traverse scanner folders
for scanner_model in sorted(os.listdir(flatfield_path)):
    scanner_folder = os.path.join(flatfield_path, scanner_model)
    if not os.path.isdir(scanner_folder):
        continue

    for file_name in os.listdir(scanner_folder):
        file_path = os.path.join(scanner_folder, file_name)
        if not os.path.isfile(file_path):
            continue

        # Try to read image format
        try:
            with Image.open(file_path) as img:
                img_format = img.format
        except:
            img_format = "Unreadable"

        metadata.append({
            "scanner_model": scanner_model,
            "file_name": file_name,
            "format": img_format
        })

# Create DataFrame
df = pd.DataFrame(metadata)

# --- First Graph: Images per Scanner Model ---
scanner_counts = df['scanner_model'].value_counts().sort_index()
plt.figure(figsize=(10, 6))
scanner_counts.plot(kind='bar', color='skyblue', edgecolor='black')
plt.title("üìä Number of Images per Scanner Model (Flatfield)", fontsize=14)
plt.xlabel("Scanner Model", fontsize=12)
plt.ylabel("Number of Images", fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# --- Second Graph: Image Format Distribution ---
format_counts = df['format'].value_counts().sort_index()
plt.figure(figsize=(8, 5))
format_counts.plot(kind='bar', color='salmon', edgecolor='black')
plt.title("üñºÔ∏è Image Format Distribution (Flatfield)", fontsize=14)
plt.xlabel("Image Format", fontsize=12)
plt.ylabel("Number of Files", fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import os
import cv2
import matplotlib.pyplot as plt

# Paths
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"

# Traverse each scanner folder
for scanner_model in sorted(os.listdir(flatfield_path)):
    scanner_folder = os.path.join(flatfield_path, scanner_model)
    if not os.path.isdir(scanner_folder):
        continue

    # Find first readable image
    sample_image = None
    for file_name in sorted(os.listdir(scanner_folder)):
        file_path = os.path.join(scanner_folder, file_name)
        if not os.path.isfile(file_path):
            continue

        image = cv2.imread(file_path)
        if image is not None:
            sample_image = image
            sample_path = file_path
            break

    if sample_image is None:
        print(f"‚ùå No readable image found in {scanner_model}")
        continue

    # Convert to grayscale
    gray_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)

    # Display side by side
    plt.figure(figsize=(10, 5))
    plt.suptitle(f"Scanner: {scanner_model}", fontsize=14)

    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB))
    plt.title("Original")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(gray_image, cmap="gray")
    plt.title("Grayscale")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Input path
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"

# Traverse each scanner folder
for scanner_model in sorted(os.listdir(flatfield_path)):
    scanner_folder = os.path.join(flatfield_path, scanner_model)
    if not os.path.isdir(scanner_folder):
        continue

    print(f"\nüìÅ Scanner Model: {scanner_model}")

    # Process each image (limit to 3 per folder)
    image_files = sorted(os.listdir(scanner_folder))
    count = 0

    for file_name in image_files:
        if count >= 3:
            break

        file_path = os.path.join(scanner_folder, file_name)
        if not os.path.isfile(file_path):
            continue

        image = cv2.imread(file_path)
        if image is None:
            print(f"‚ùå Skipped unreadable file: {file_name}")
            continue

        # Step 1: Grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Step 2: Resize
        resized = cv2.resize(gray, (256, 256))

        # Step 3: Denoise
        denoised = cv2.GaussianBlur(resized, (5, 5), 0)

        # Step 4: Normalize
        normalized = denoised.astype("float32") / 255.0

        # Step 5: Display all stages
        plt.figure(figsize=(12, 6))
        plt.suptitle(f"{scanner_model} ‚Äî {file_name}", fontsize=14)

        plt.subplot(1, 4, 1)
        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        plt.title("Original")
        plt.axis("off")

        plt.subplot(1, 4, 2)
        plt.imshow(gray, cmap="gray")
        plt.title("Grayscale")
        plt.axis("off")

        plt.subplot(1, 4, 3)
        plt.imshow(denoised, cmap="gray")
        plt.title("Denoised")
        plt.axis("off")

        plt.subplot(1, 4, 4)
        plt.imshow(normalized, cmap="gray")
        plt.title("Normalized")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

        count += 1

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"
feature_summary = {}

def extract_features(img_gray):
    img_resized = cv2.resize(img_gray, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0

    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])
    high_pass = cv2.filter2D(img_normalized, -1, kernel)

    coeffs2 = pywt.dwt2(img_normalized, 'db1')
    approx, (horiz, vert, diag) = coeffs2

    return high_pass, approx, horiz, vert, diag

# üîÅ Traverse scanner model folders
for scanner in sorted(os.listdir(flatfield_path)):
    scanner_path = os.path.join(flatfield_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    tif_files = [f for f in os.listdir(scanner_path) if f.lower().endswith(('.tif', '.tiff'))]
    valid_count = 0
    first_preview_done = False

    for fname in tif_files:
        img_path = os.path.join(scanner_path, fname)
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
        if img is None:
            print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
            continue

        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        hp, approx, horiz, vert, diag = extract_features(img_gray)
        valid_count += 1

        if not first_preview_done:
            titles = ["High-Pass", "Approximation", "Horizontal", "Vertical", "Diagonal"]
            images = [hp, approx, horiz, vert, diag]
            fig, axs = plt.subplots(1, 5, figsize=(20, 4))
            for j in range(5):
                axs[j].imshow(images[j], cmap='gray')
                axs[j].set_title(titles[j])
                axs[j].axis('off')
            plt.suptitle(f"{scanner} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()
            first_preview_done = True

    feature_summary[scanner] = valid_count

print("\nüìä Feature Extraction Summary for Flatfield:")
for scanner, count in feature_summary.items():
    print(f"{scanner}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Base path
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"
feature_summary = {}

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üîÅ Traverse scanner model folders
for scanner in sorted(os.listdir(flatfield_path)):
    scanner_path = os.path.join(flatfield_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    tif_files = [f for f in os.listdir(scanner_path) if f.lower().endswith(('.tif', '.tiff'))]
    valid_count = 0
    first_preview_done = False

    for fname in tif_files:
        img_path = os.path.join(scanner_path, fname)
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
        if img is None:
            print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
            continue

        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        img_pre = preprocess_image(img_gray)

        fft_img = extract_fft(img_pre)
        prnu_img = extract_prnu(img_pre)

        if not first_preview_done:
            fig, axs = plt.subplots(1, 3, figsize=(15, 4))
            axs[0].imshow(img_pre, cmap='gray')
            axs[0].set_title("Preprocessed")

            axs[1].imshow(fft_img, cmap='gray')
            axs[1].set_title("FFT Spectrum")

            axs[2].imshow(prnu_img, cmap='gray')
            axs[2].set_title("PRNU Residual")

            plt.suptitle(f"{scanner} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()
            first_preview_done = True

        valid_count += 1

    feature_summary[scanner] = valid_count

print("\nüìä Feature Extraction Summary for Flatfield:")
for scanner, count in feature_summary.items():
    print(f"{scanner}: {count} images processed")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"
image_counts = {}
histograms = []

# üîÅ Traverse scanner model folders
for scanner in sorted(os.listdir(flatfield_path)):
    scanner_path = os.path.join(flatfield_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    tif_files = [f for f in os.listdir(scanner_path) if f.lower().endswith(('.tif', '.tiff'))]
    image_counts[scanner] = len(tif_files)

    for fname in tif_files[:2]:  # Preview first 2 for histogram
        img_path = os.path.join(scanner_path, fname)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
            continue

        img_resized = cv2.resize(img, (512, 512))
        hist = cv2.calcHist([img_resized], [0], None, [256], [0, 256])
        histograms.append((f"{scanner} ‚Üí {fname}", hist))

for label, hist in histograms:
    plt.figure(figsize=(6, 3))
    plt.plot(hist, color='gray')
    plt.title(f"Histogram: {label}", fontsize=10)
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()

labels = list(image_counts.keys())
counts = list(image_counts.values())

plt.figure(figsize=(12, 6))
plt.bar(labels, counts, color='skyblue')
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Images")
plt.title("üìä Image Count per Scanner Model (Flatfield)")
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import pywt
from PIL import Image

# üìÅ Input and output paths
flatfield_path = "/content/drive/MyDrive/InfosysVirtual/Flatfield"
output_base = "/content/drive/MyDrive/InfosysVirtual/Flatfield_Features"

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üì¶ Save image as PNG
def save_image(array, path):
    array = np.clip(array * 255, 0, 255).astype(np.uint8)
    Image.fromarray(array).save(path)

# üîÅ Traverse scanner folders
for scanner in sorted(os.listdir(flatfield_path)):
    scanner_path = os.path.join(flatfield_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    tif_files = [f for f in os.listdir(scanner_path) if f.lower().endswith(('.tif', '._150.tif','.tiff'))]

    for fname in tif_files:
        img_path = os.path.join(scanner_path, fname)
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
        if img is None:
            print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
            continue

        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        img_pre = preprocess_image(img_gray)
        fft_img = extract_fft(img_pre)
        prnu_img = extract_prnu(img_pre)

        # üìÅ Create output folder
        save_folder = os.path.join(output_base, scanner)
        os.makedirs(save_folder, exist_ok=True)

        # üßæ Save images
        base_name = os.path.splitext(fname)[0]
        save_image(img_pre, os.path.join(save_folder, f"{base_name}_preprocessed.png"))
        save_image(fft_img / np.max(fft_img), os.path.join(save_folder, f"{base_name}_fft.png"))
        save_image(prnu_img / np.max(np.abs(prnu_img)), os.path.join(save_folder, f"{base_name}_prnu.png"))

        print(f"‚úÖ Saved: {scanner}/{fname}")

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive

!ls /content/drive/MyDrive/InfosysVirtual

epson_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia/EpsonV550/150"

import os

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
scanner_counts = {}

for scanner in os.listdir(base_path):
    scanner_path = os.path.join(base_path, scanner)
    if os.path.isdir(scanner_path):
        count = sum(fname.lower().endswith('.tif') for fname in os.listdir(scanner_path))
        scanner_counts[scanner] = count

for scanner, count in scanner_counts.items():
    print(f"{scanner}: {count} .tif files")

import os
import cv2
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
scanner_summary = {}

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        dpi_summary[dpi] = len(tif_files)

        # Convert and preview first 2 grayscale images
        for fname in tif_files[:2]:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                plt.figure(figsize=(4, 4))
                plt.title(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
                plt.imshow(img, cmap='gray')
                plt.axis('off')
                plt.show()
            else:
                print(f"‚ö†Ô∏è Could not read: {img_path}")

    scanner_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Grayscale Conversion Summary (Preview Only):")
for scanner, dpi_data in scanner_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} files converted")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
preprocess_summary = {}

def preprocess_image(img):
    # Resize to standard size (optional)
    img_resized = cv2.resize(img, (512, 512))

    # Histogram equalization
    img_eq = cv2.equalizeHist(img_resized)

    return img_eq

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_pre = preprocess_image(img)

            # Show original vs preprocessed
            fig, axs = plt.subplots(1, 2, figsize=(8, 4))
            axs[0].imshow(img, cmap='gray')
            axs[0].set_title("Original")
            axs[0].axis('off')

            axs[1].imshow(img_pre, cmap='gray')
            axs[1].set_title("Preprocessed")
            axs[1].axis('off')

            plt.suptitle(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Preprocessing Summary (Preview Only):")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} images preprocessed")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

base_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
preprocess_summary = {}

def preprocess_image(img):
    # Resize to standard size
    img_resized = cv2.resize(img, (512, 512))

    # Denoise using Gaussian blur
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)

    # Normalize to [0, 1] float
    img_normalized = img_denoised.astype(np.float32) / 255.0

    return img_resized, img_denoised, img_normalized

for scanner in sorted(os.listdir(base_path)):
    scanner_path = os.path.join(base_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith('.tif')]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_resized, img_denoised, img_normalized = preprocess_image(img)

            # Show original, denoised, normalized
            fig, axs = plt.subplots(1, 3, figsize=(12, 4))
            axs[0].imshow(img_resized, cmap='gray')
            axs[0].set_title("Resized")
            axs[0].axis('off')

            axs[1].imshow(img_denoised, cmap='gray')
            axs[1].set_title("Denoised")
            axs[1].axis('off')

            axs[2].imshow(img_normalized, cmap='gray')
            axs[2].set_title("Normalized")
            axs[2].axis('off')

            plt.suptitle(f"{scanner} - {dpi} DPI\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Preprocessing Summary (Denoise + Normalize):")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ({dpi} DPI): {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Define base path
wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
feature_summary = {}

# üßº Preprocessing + Feature Extraction
def extract_features(img_gray):
    img_resized = cv2.resize(img_gray, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0

    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])
    high_pass = cv2.filter2D(img_normalized, -1, kernel)

    coeffs2 = pywt.dwt2(img_normalized, 'db1')
    approx, (horiz, vert, diag) = coeffs2

    return high_pass, approx, horiz, vert, diag

# üîÅ Traverse folders
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for i, fname in enumerate(tif_files):
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            hp, approx, horiz, vert, diag = extract_features(img_gray)
            valid_count += 1

            if i == 0:
                titles = ["High-Pass", "Approximation", "Horizontal", "Vertical", "Diagonal"]
                images = [hp, approx, horiz, vert, diag]
                fig, axs = plt.subplots(1, 5, figsize=(20, 4))
                for j in range(5):
                    axs[j].imshow(images[j], cmap='gray')
                    axs[j].set_title(titles[j])
                    axs[j].axis('off')
                plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
                plt.tight_layout()
                plt.show()

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary for Wikipedia:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Base path
wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
feature_summary = {}

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üîÅ Traverse folders
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)

            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            fig, axs = plt.subplots(1, 3, figsize=(15, 4))
            axs[0].imshow(img_pre, cmap='gray')
            axs[0].set_title("Preprocessed")

            axs[1].imshow(fft_img, cmap='gray')
            axs[1].set_title("FFT Spectrum")

            axs[2].imshow(prnu_img, cmap='gray')
            axs[2].set_title("PRNU Residual")

            plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary for Wikipedia:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import matplotlib.pyplot as plt

wikipedia_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
histograms = []

# Collect histograms
for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        if not tif_files:
            continue

        # Use first valid image
        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_resized = cv2.resize(img_gray, (512, 512))
            hist = cv2.calcHist([img_resized], [0], None, [256], [0, 256])
            label = f"{scanner} ‚Üí {dpi}"
            histograms.append((label, hist))
            break  # Only one image per DPI

# Plot histograms
for label, hist in histograms:
    plt.figure(figsize=(6, 3))
    plt.plot(hist, color='gray')
    plt.title(f"Histogram: {label}", fontsize=10)
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()

image_counts = {}

for scanner in sorted(os.listdir(wikipedia_path)):
    scanner_path = os.path.join(wikipedia_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        dpi_summary[dpi] = len(tif_files)

    image_counts[scanner] = dpi_summary

# Flatten for bar graph
labels = []
counts = []

for scanner, dpi_data in image_counts.items():
    for dpi, count in dpi_data.items():
        labels.append(f"{scanner}\n{dpi}")
        counts.append(count)

plt.figure(figsize=(12, 6))
plt.bar(labels, counts, color='skyblue')
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Images")
plt.title("üìä Image Count per Scanner/DPI Folder (Wikipedia)")
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt
from PIL import Image

# üìÅ Input and output paths
input_path = "/content/drive/MyDrive/InfosysVirtual/Wikipedia"
output_base = "/content/drive/MyDrive/InfosysVirtual/Wikipedia_Features"

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üì¶ Save image as PNG
def save_image(array, path):
    array = np.clip(array * 255, 0, 255).astype(np.uint8)
    Image.fromarray(array).save(path)

# üîÅ Traverse folders
for scanner in sorted(os.listdir(input_path)):
    scanner_path = os.path.join(input_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # üìÅ Create output folder
            save_folder = os.path.join(output_base, scanner, dpi)
            os.makedirs(save_folder, exist_ok=True)

            # üßæ Save images
            base_name = os.path.splitext(fname)[0]
            save_image(img_pre, os.path.join(save_folder, f"{base_name}_preprocessed.png"))
            save_image(fft_img / np.max(fft_img), os.path.join(save_folder, f"{base_name}_fft.png"))
            save_image(prnu_img / np.max(np.abs(prnu_img)), os.path.join(save_folder, f"{base_name}_prnu.png"))

            print(f"‚úÖ Saved: {scanner}/{dpi}/{fname}")

# üîó Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# üìÅ Step 2: Define Official folder path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"

# üßº Step 3: Preprocessing function
import cv2
import numpy as np

def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_resized, img_denoised, img_normalized

import os
import cv2
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
grayscale_summary = {}

for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

            # Convert to grayscale if needed
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue
            elif len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img  # Already grayscale

            # Preview
            plt.figure(figsize=(4, 4))
            plt.imshow(img_gray, cmap='gray')
            plt.title(f"{scanner} ‚Üí {dpi}\n{fname}", fontsize=10)
            plt.axis('off')
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    grayscale_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Grayscale Conversion Summary for Official Folder:")
for scanner, dpi_data in grayscale_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images converted")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
preprocess_summary = {}

def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_resized, img_denoised, img_normalized

for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            img_resized, img_denoised, img_normalized = preprocess_image(img_gray)

            # Visual preview
            fig, axs = plt.subplots(1, 3, figsize=(12, 4))
            axs[0].imshow(img_resized, cmap='gray')
            axs[0].set_title("Resized")
            axs[0].axis('off')

            axs[1].imshow(img_denoised, cmap='gray')
            axs[1].set_title("Denoised")
            axs[1].axis('off')

            axs[2].imshow(img_normalized, cmap='gray')
            axs[2].set_title("Normalized")
            axs[2].axis('off')

            plt.suptitle(f"{scanner} ‚Üí {dpi}\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

print("\nüìä Preprocessing Summary for Official Folder:")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Define base path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
feature_summary = {}

# üßº Preprocessing + Feature Extraction
def extract_features(img_gray):
    # Resize
    img_resized = cv2.resize(img_gray, (512, 512))

    # Denoise
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)

    # Normalize
    img_normalized = img_denoised.astype(np.float32) / 255.0

    # High-pass filter
    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])
    high_pass = cv2.filter2D(img_normalized, -1, kernel)

    # Wavelet decomposition
    coeffs2 = pywt.dwt2(img_normalized, 'db1')  # Daubechies 1
    approx, (horiz, vert, diag) = coeffs2

    return high_pass, approx, horiz, vert, diag

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for i, fname in enumerate(tif_files):
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            # Extract features
            hp, approx, horiz, vert, diag = extract_features(img_gray)
            valid_count += 1

            # Show preview for first image only
            if i == 0:
                titles = ["High-Pass", "Approximation", "Horizontal", "Vertical", "Diagonal"]
                images = [hp, approx, horiz, vert, diag]
                fig, axs = plt.subplots(1, 5, figsize=(20, 4))
                for j in range(5):
                    axs[j].imshow(images[j], cmap='gray')
                    axs[j].set_title(titles[j])
                    axs[j].axis('off')
                plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
                plt.tight_layout()
                plt.show()

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Base path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
feature_summary = {}

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            # Preprocess
            img_pre = preprocess_image(img_gray)

            # Extract features
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # Visualize
            fig, axs = plt.subplots(1, 3, figsize=(15, 4))
            axs[0].imshow(img_pre, cmap='gray')
            axs[0].set_title("Preprocessed")

            axs[1].imshow(fft_img, cmap='gray')
            axs[1].set_title("FFT Spectrum")

            axs[2].imshow(prnu_img, cmap='gray')
            axs[2].set_title("PRNU Residual")

            plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä FFT + PRNU Feature Extraction Summary:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
image_counts = {}
histograms = []

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        dpi_summary[dpi] = len(tif_files)

        for fname in tif_files[:2]:  # Limit to first 2 for histogram preview
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            img_resized = cv2.resize(img, (512, 512))
            hist = cv2.calcHist([img_resized], [0], None, [256], [0, 256])
            histograms.append((f"{scanner} ‚Üí {dpi} ‚Üí {fname}", hist))

    image_counts[scanner] = dpi_summary

# Show histograms
for label, hist in histograms:
    plt.figure(figsize=(6, 3))
    plt.plot(hist, color='gray')
    plt.title(f"Histogram: {label}", fontsize=10)
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()

# Flatten counts for bar graph
labels = []
counts = []

for scanner, dpi_data in image_counts.items():
    for dpi, count in dpi_data.items():
        labels.append(f"{scanner}\n{dpi}")
        counts.append(count)

plt.figure(figsize=(12, 6))
plt.bar(labels, counts, color='skyblue')
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Images")
plt.title("üìä Image Count per Scanner/DPI Folder")
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

from PIL import Image

# üìÅ Input and output paths
input_path = "/content/drive/MyDrive/InfosysVirtual/Official"
output_base = "/content/drive/MyDrive/InfosysVirtual/Official_Features"

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üì¶ Save image as PNG
def save_image(array, path):
    array = np.clip(array * 255, 0, 255).astype(np.uint8)
    Image.fromarray(array).save(path)

# üîÅ Traverse folders
for scanner in sorted(os.listdir(input_path)):
    scanner_path = os.path.join(input_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # üìÅ Create output folder
            save_folder = os.path.join(output_base, scanner, dpi)
            os.makedirs(save_folder, exist_ok=True)

            # üßæ Save images
            base_name = os.path.splitext(fname)[0]
            save_image(img_pre, os.path.join(save_folder, f"{base_name}_preprocessed.png"))
            save_image(fft_img / np.max(fft_img), os.path.join(save_folder, f"{base_name}_fft.png"))
            save_image(prnu_img / np.max(np.abs(prnu_img)), os.path.join(save_folder, f"{base_name}_prnu.png"))

            print(f"‚úÖ Saved: {scanner}/{dpi}/{fname}")

import os
import glob
import pandas as pd

root_path = "/content/drive/MyDrive/InfosysVirtual/Official_Features"
lbp_features = []
labels = []
scanner_counts = {}

def extract_lbp(image_path):
    import cv2
    import numpy as np
    from skimage.feature import local_binary_pattern

    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        return None

    radius = 1
    n_points = 8 * radius
    lbp = local_binary_pattern(image, n_points, radius, method="uniform")
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
    hist = hist.astype("float")
    hist /= (hist.sum() + 1e-6)
    return hist

for scanner_model in os.listdir(root_path):
    model_path = os.path.join(root_path, scanner_model)
    if not os.path.isdir(model_path):
        continue

    count = 0
    for sample_folder in os.listdir(model_path):
        sample_path = os.path.join(model_path, sample_folder)
        if not os.path.isdir(sample_path):
            continue

        image_candidates = glob.glob(os.path.join(sample_path, "*_preprocessed.png"))
        if not image_candidates:
            print("‚ùå No LBP image found in:", sample_path)
            continue

        image_path = image_candidates[0]
        print("‚úÖ Using:", image_path)

        features = extract_lbp(image_path)
        if features is None:
            print("‚ö†Ô∏è LBP failed for:", image_path)
            continue

        lbp_features.append(features)
        labels.append(scanner_model)
        count += 1

    scanner_counts[scanner_model] = count

# Convert to DataFrame
df_lbp = pd.DataFrame(lbp_features)
df_lbp["label"] = labels

# Summary table
summary_df = pd.DataFrame.from_dict(scanner_counts, orient="index", columns=["Samples"])
print("\nüìä Sample Count per Scanner Model:")
print(summary_df)

# Preview extracted features
print("\nüîç LBP Feature DataFrame Preview:")
print(df_lbp.head())

from google.colab import drive
drive.mount('/content/drive')

official_base = '/content/drive/MyDrive/InfosysVirtual/Official'

# === Imports ===
import os, cv2, numpy as np, pandas as pd
from PIL import Image
from tqdm import tqdm
from skimage.feature import local_binary_pattern
from scipy.fftpack import fft2
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb
from sklearn.linear_model import LogisticRegression
import torch
import torchvision.models as models
import torchvision.transforms as transforms

# === Feature extraction ===
def extract_handcrafted(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if img is None: return None
    img = cv2.resize(img, (128, 128))
    lbp = local_binary_pattern(img, P=8, R=1, method='uniform')
    lbp_hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59))
    fft = np.abs(fft2(img))
    fft_mean, fft_std = np.mean(fft), np.std(fft)
    energy = np.sum(img ** 2)
    return np.concatenate([lbp_hist, [fft_mean, fft_std, energy]])

resnet = models.resnet18(pretrained=True)
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Build dataset ===
features_hc, features_cnn, labels = [], [], []
label_map, label_counter = {}, 0

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    hc = extract_handcrafted(path)
                    cnn = extract_cnn(path)
                    if hc is not None and cnn is not None:
                        features_hc.append(hc)
                        features_cnn.append(cnn)
                        labels.append(label_map[key])

X_hc = np.array(features_hc)
X_cnn = np.array(features_cnn)
y = np.array(labels)

# === K-Fold setup ===
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
meta_preds, meta_labels = [], []

for fold, (train_idx, val_idx) in enumerate(kf.split(X_hc, y)):
    print(f"\nüìÅ Fold {fold+1}")

    X_train_hc, X_val_hc = X_hc[train_idx], X_hc[val_idx]
    X_train_cnn, X_val_cnn = X_cnn[train_idx], X_cnn[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]

    # Train base models
    svm = SVC(probability=True).fit(X_train_hc, y_train)
    rf = RandomForestClassifier().fit(X_train_hc, y_train)
    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss').fit(X_train_hc, y_train)
    lgb_model = lgb.LGBMClassifier().fit(X_train_hc, y_train)
    cnn_clf = LogisticRegression(max_iter=1000).fit(X_train_cnn, y_train)

    # Validation predictions
    svm_val = svm.predict_proba(X_val_hc)
    rf_val = rf.predict_proba(X_val_hc)
    xgb_val = xgb_model.predict_proba(X_val_hc)
    lgb_val = lgb_model.predict_proba(X_val_hc)

    stacked_val = np.hstack([svm_val, rf_val, xgb_val, lgb_val, X_val_cnn])
    meta_preds.append(stacked_val)
    meta_labels.append(y_val)

# === Train final meta-model ===
X_meta = np.vstack(meta_preds)
y_meta = np.hstack(meta_labels)
meta_model = LogisticRegression(max_iter=1000)
meta_model.fit(X_meta, y_meta)

final_preds = meta_model.predict(X_meta)
acc = accuracy_score(y_meta, final_preds)
print(f"\n‚úÖ K-Fold Ensemble Accuracy: {acc:.2%}")

# === Imports ===
import os, numpy as np
from PIL import Image
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torchvision.models as models
import torchvision.transforms as transforms

# === Step 1: CNN feature extractor ===
resnet = models.resnet18(pretrained=True)
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Step 2: Build dataset ===
features_cnn, labels = [], []
label_map, label_counter = {}, 0

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        features_cnn.append(cnn)
                        labels.append(label_map[key])

X_cnn = np.array(features_cnn)
y = np.array(labels)

# === Step 3: Train CNN classifier ===
clf = LogisticRegression(max_iter=1000)
clf.fit(X_cnn, y)

# === Step 4: Accuracy ===
acc = accuracy_score(y, clf.predict(X_cnn))
print(f"\n‚úÖ CNN (ResNet18) Training Accuracy: {acc:.2%}")

# === Step 5: Confusion Matrix ===
cm = confusion_matrix(y, clf.predict(X_cnn))
xticks = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]
sns.heatmap(cm, annot=True, fmt='d', xticklabels=xticks, yticklabels=xticks, cmap='Blues')
plt.title("CNN (ResNet18) Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from collections import defaultdict

# === Step: Map folder to predictions ===
folder_accuracy = defaultdict(lambda: {'correct': 0, 'total': 0})

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        pred = clf.predict(cnn.reshape(1, -1))[0]
                        actual = label_map[f"{source}_{model}"]
                        folder_key = f"{source}_{model}_{res}"
                        folder_accuracy[folder_key]['total'] += 1
                        if pred == actual:
                            folder_accuracy[folder_key]['correct'] += 1

# === Step: Print folder-wise accuracy ===
print("\nüìÇ Folder-wise Accuracy:")
for folder, stats in sorted(folder_accuracy.items()):
    correct = stats['correct']
    total = stats['total']
    acc = correct / total if total > 0 else 0
    print(f"{folder}: {acc:.2%} ({correct}/{total})")

# === Imports ===
import os, numpy as np
from PIL import Image
from collections import Counter
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import cv2

# === Step 1: CNN Feature Extractor ===
resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Step 2: Build Dataset from Official + Wikipedia ===
features_cnn, labels = [], []
label_map, label_counter = {}, 0
sample_image_path = None  # For Grad-CAM

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        features_cnn.append(cnn)
                        labels.append(label_map[key])
                        if sample_image_path is None:
                            sample_image_path = path  # First valid image for Grad-CAM

X_cnn = np.array(features_cnn)
y = np.array(labels)

# === Step 3: Train Logistic Regression Classifier ===
clf = LogisticRegression(max_iter=1000)
clf.fit(X_cnn, y)

# === Step 4: Training Accuracy ===
y_pred = clf.predict(X_cnn)
acc = accuracy_score(y, y_pred)
print(f"\n‚úÖ CNN (ResNet18) Training Accuracy: {acc:.2%}")

# === Step 5: PRNU File Counts per Scanner ===
scanner_counts = Counter(labels)
print("\nüìÅ Total PRNU Files per Scanner:")
for key, idx in sorted(label_map.items(), key=lambda x: x[1]):
    print(f"{key}: {scanner_counts[idx]} files")

# === Step 6: Confusion Matrix ===
cm = confusion_matrix(y, y_pred)
xticks = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]
sns.heatmap(cm, annot=True, fmt='d', xticklabels=xticks, yticklabels=xticks, cmap='Blues')
plt.title("CNN (ResNet18) Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# === Step 7: Classification Report ===
print("\nüìä Precision, Recall, F1-score:")
print(classification_report(y, y_pred, target_names=xticks, digits=2))

# === Step 8: Grad-CAM Visualization ===
gradients = []
activations = []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

# Load and preprocess image
img = Image.open(sample_image_path).convert('RGB')
rgb_image = np.array(img) / 255.0
tensor = transform(img).unsqueeze(0)

# Forward + backward pass
resnet.zero_grad()
output = resnet(tensor)
output[0].mean().backward()

# Grad-CAM computation
grad = gradients[0].squeeze().detach().numpy()
act = activations[0].squeeze().detach().numpy()
weights = np.mean(grad, axis=(1, 2))
cam = np.zeros(act.shape[1:], dtype=np.float32)
for i, w in enumerate(weights):
    cam += w * act[i]

cam = np.maximum(cam, 0)
cam = cv2.resize(cam, (rgb_image.shape[1], rgb_image.shape[0]))
cam = cam / cam.max()

# Overlay heatmap
heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
overlay = np.uint8(255 * rgb_image)
combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

# Display original and Grad-CAM
fig, axs = plt.subplots(1, 2, figsize=(10, 5))
axs[0].imshow(rgb_image)
axs[0].set_title("Original PRNU Image")
axs[0].axis('off')

axs[1].imshow(combined[:, :, ::-1])
axs[1].set_title("Grad-CAM Overlay")
axs[1].axis('off')
plt.tight_layout()
plt.show()

import joblib
import os

# Create models directory if it doesn't exist
model_dir = '/content/drive/MyDrive/InfosysVirtual/models'
os.makedirs(model_dir, exist_ok=True)

# Save trained classifier
joblib.dump(clf, os.path.join(model_dir, 'logreg_cnn.pkl'))

# Save label map
joblib.dump(label_map, os.path.join(model_dir, 'label_map.pkl'))

print("‚úÖ Model and label map saved successfully.")

import gradio as gr
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import joblib
import cv2
import os

# === Mount Google Drive ===
from google.colab import drive
drive.mount('/content/drive')

# === Load ResNet18 Feature Extractor ===
resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# === Load Classifier and Label Map from Drive ===
model_dir = '/content/drive/MyDrive/InfosysVirtual/models'
clf = joblib.load(os.path.join(model_dir, 'logreg_cnn.pkl'))
label_map = joblib.load(os.path.join(model_dir, 'label_map.pkl'))
inv_label_map = {v: k for k, v in label_map.items()}

# === Grad-CAM Setup ===
gradients, activations = [], []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

# === Prediction Function ===
def predict_scanner(image):
    img = image.convert("RGB")
    tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        features = resnet(tensor).squeeze().numpy()

    pred = clf.predict([features])[0]
    proba = clf.predict_proba([features])[0][pred]
    label = inv_label_map[pred]

    # Grad-CAM
    resnet.zero_grad()
    output = resnet(tensor)
    output[0].mean().backward()

    grad = gradients[0].squeeze().detach().numpy()
    act = activations[0].squeeze().detach().numpy()
    weights = np.mean(grad, axis=(1, 2))
    cam = np.zeros(act.shape[1:], dtype=np.float32)
    for i, w in enumerate(weights):
        cam += w * act[i]
    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (img.size[0], img.size[1]))
    cam = cam / cam.max()

    rgb_image = np.array(img) / 255.0
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    overlay = np.uint8(255 * rgb_image)
    combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

    return label, f"{proba:.2f}", image, combined[:, :, ::-1]

# === Custom Gradio Frontend ===
with gr.Blocks(css=".gradio-container {background-color: #ffffff; font-family: 'Segoe UI'; color: #2c3e50;}") as app:
    gr.Markdown("""
    <div style="text-align:center;">
        <h1 style="color:#2c3e50;">üìÑ TraceFinder - Forensic Scanner Identification</h1>
        <p style="font-size:16px;">Upload a scanned document image to identify the source scanner device using CNN features + Logistic Regression.</p>
        <p style="font-size:14px; color:#7f8c8d;">Supported formats: .tiff, .png, .jpeg, .jpg. No preprocessing or PRNU extraction required.</p>
    </div>
    """)

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="üì§ Upload Document Image", image_mode="RGB", sources=["upload", "clipboard"])
            submit_btn = gr.Button("üîç Identify Scanner")
        with gr.Column(scale=1):
            label_output = gr.Text(label="üîñ Predicted Scanner Model")
            confidence_output = gr.Text(label="üìä Confidence Score")

    with gr.Row():
        with gr.Column(scale=1):
            uploaded_preview = gr.Image(label="üñºÔ∏è Uploaded Image Preview")
        with gr.Column(scale=1):
            gradcam_output = gr.Image(label="üî• Grad-CAM Visualization")

    submit_btn.click(
        fn=predict_scanner,
        inputs=image_input,
        outputs=[label_output, confidence_output, uploaded_preview, gradcam_output]
    )

    gr.Markdown("<p style='text-align:center; font-size:12px; color:#95a5a6;'>Developed by Ashwini | Infosys Virtual Project</p>")

app.launch()

app_code = '''
import gradio as gr
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import joblib
import cv2

# === Load ResNet18 and Classifier ===
resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

clf = joblib.load("logreg_cnn.pkl")
label_map = joblib.load("label_map.pkl")
inv_label_map = {v: k for k, v in label_map.items()}

gradients, activations = [], []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

# === Prediction Function ===
def predict_scanner(image):
    img = image.convert("RGB")
    tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        features = resnet(tensor).squeeze().numpy()

    pred = clf.predict([features])[0]
    proba = clf.predict_proba([features])[0][pred]
    label = inv_label_map[pred]

    # Grad-CAM
    resnet.zero_grad()
    output = resnet(tensor)
    output[0].mean().backward()

    grad = gradients[0].squeeze().detach().numpy()
    act = activations[0].squeeze().detach().numpy()
    weights = np.mean(grad, axis=(1, 2))
    cam = np.zeros(act.shape[1:], dtype=np.float32)
    for i, w in enumerate(weights):
        cam += w * act[i]
    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (img.size[0], img.size[1]))
    cam = cam / cam.max()

    rgb_image = np.array(img) / 255.0
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    overlay = np.uint8(255 * rgb_image)
    combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

    return label, f"{proba:.2f}", combined[:, :, ::-1], image

# === Gradio UI ===
with gr.Blocks(css=".gradio-container {background-color: #ffffff; font-family: 'Segoe UI'; color: #2c3e50;}") as app:
    gr.Markdown("""
    <div style="text-align:center;">
        <h1 style="color:#2c3e50;">üìÑ TraceFinder - Forensic Scanner Identification</h1>
        <p style="font-size:16px;">Upload a scanned document image to identify the source scanner device.</p>
        <p style="font-size:14px; color:#7f8c8d;">Supported formats: .tiff, .png, .jpeg, .jpg</p>
    </div>
    """)

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="üì§ Upload Document Image", image_mode="RGB", sources=["upload", "clipboard"])
            submit_btn = gr.Button("üîç Identify Scanner")
        with gr.Column(scale=1):
            label_output = gr.Text(label="üîñ Predicted Scanner Model")
            confidence_output = gr.Text(label="üìä Confidence Score")
            gradcam_output = gr.Image(label="üß≠ Grad-CAM Visualization")
            uploaded_image_display = gr.Image(label="üñºÔ∏è Uploaded Image Preview")

    submit_btn.click(
        fn=predict_scanner,
        inputs=image_input,
        outputs=[label_output, confidence_output, gradcam_output, uploaded_image_display]
    )

    gr.Markdown("<p style='text-align:center; font-size:12px; color:#95a5a6;'>Developed by Ashwini | Infosys Virtual Project</p>")

app.launch()
'''
with open("app.py", "w") as f:
    f.write(app_code)

reqs = '''
gradio
torch
torchvision
scikit-learn
joblib
pillow
opencv-python
'''
with open("requirements.txt", "w") as f:
    f.write(reqs)

from google.colab import files
files.download("app.py")
files.download("requirements.txt")
files.download("/content/drive/MyDrive/InfosysVirtual/models/logreg_cnn.pkl")
files.download("/content/drive/MyDrive/InfosysVirtual/models/label_map.pkl")

import os
import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim

# === Mount Google Drive ===
from google.colab import drive
drive.mount('/content/drive')

# === Define Dataset Folder ===
DATASET_PATH = "/content/drive/MyDrive/InfosysVirtual/Official/Canon120-2/300"

# === Temporary memory (session-based)
temp_memory = []

# === Function: Compare two images using SSIM
def is_same_image(img1, img2):
    try:
        img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        img1_gray = cv2.resize(img1_gray, (256, 256))
        img2_gray = cv2.resize(img2_gray, (256, 256))
        score, _ = ssim(img1_gray, img2_gray, full=True)
        return score > 0.95
    except Exception as e:
        print("‚ö†Ô∏è Error comparing images:", e)
        return False

# === Step 1: Get input image path
input_path = input("üì§ Enter full path of image to check: ").strip()
input_image = cv2.imread(input_path)

if input_image is None:
    print("‚ùå Could not load input image. Check the path or format.")
    exit()

found_in_dataset = False
found_in_temp = False

# === Step 2: Check against dataset folder
for file in os.listdir(DATASET_PATH):
    if file.lower().endswith((".tif", ".tiff", ".png", ".jpg", ".jpeg")):
        file_path = os.path.join(DATASET_PATH, file)
        dataset_image = cv2.imread(file_path)
        if dataset_image is None:
            continue
        if is_same_image(input_image, dataset_image):
            found_in_dataset = True
            break

# === Step 3: Check against temporary memory
for temp_img in temp_memory:
    if is_same_image(input_image, temp_img):
        found_in_temp = True
        break

# === Step 4: Update memory
temp_memory.append(input_image)

# === Step 5: Print Results
print("\nüîç Scan Results:")
if found_in_dataset:
    print("‚úÖ Image FOUND in dataset folder.")
else:
    print("‚ùå Image NOT found in dataset folder.")

if found_in_temp:
    print("‚úÖ Image FOUND in scanner temp memory (already processed).")
else:
    print("‚ùå Image NOT found in scanner temp memory.")

import numpy as np
from PIL import Image
import cv2
from skimage.metrics import structural_similarity as ssim

# === Session-based memory for scanned images ===
scanner_temp_memory = []

# === Function: Convert image to grayscale NumPy array ===
def load_and_prepare_image(path):
    try:
        img = Image.open(path).convert("RGB")
        img_np = np.array(img)
        img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        img_gray = cv2.resize(img_gray, (256, 256))
        return img_gray
    except Exception as e:
        print("‚ùå Error loading image:", e)
        return None

# === Function: Compare two grayscale images using SSIM ===
def is_same_image(img1_gray, img2_gray, threshold=0.95):
    try:
        score, _ = ssim(img1_gray, img2_gray, full=True)
        return score >= threshold
    except Exception as e:
        print("‚ö†Ô∏è Error comparing images:", e)
        return False

# === Function: Check if image already exists in memory ===
def check_scanner_temp(image_path):
    global scanner_temp_memory
    input_gray = load_and_prepare_image(image_path)
    if input_gray is None:
        return "‚ùå Could not load input image. Check the path or format."

    for stored_gray in scanner_temp_memory:
        if is_same_image(input_gray, stored_gray):
            return "‚úÖ Image already exists in scanner temp memory."

    scanner_temp_memory.append(input_gray)
    return "‚Ñπ New image added to scanner temp memory."

# === Run the check ===
if __name__ == "__main__":
    path = input("üì§ Enter full image path to check: ").strip()
    result = check_scanner_temp(path)
    print(result)