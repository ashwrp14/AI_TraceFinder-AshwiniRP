# -*- coding: utf-8 -*-
"""Official.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m0nFleoIzfh18k1IN_d8IUzX2_hQAiWg
"""

# üîó Step 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# üìÅ Step 2: Define Official folder path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"

# üßº Step 3: Preprocessing function
import cv2
import numpy as np

def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_resized, img_denoised, img_normalized

import os
import cv2
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
grayscale_summary = {}

for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

            # Convert to grayscale if needed
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue
            elif len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img  # Already grayscale

            # Preview
            plt.figure(figsize=(4, 4))
            plt.imshow(img_gray, cmap='gray')
            plt.title(f"{scanner} ‚Üí {dpi}\n{fname}", fontsize=10)
            plt.axis('off')
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    grayscale_summary[scanner] = dpi_summary

# üìä Summary Table
print("\nüìä Grayscale Conversion Summary for Official Folder:")
for scanner, dpi_data in grayscale_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images converted")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
preprocess_summary = {}

def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_resized, img_denoised, img_normalized

for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files[:2]:  # Preview first 2
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            img_resized, img_denoised, img_normalized = preprocess_image(img_gray)

            # Visual preview
            fig, axs = plt.subplots(1, 3, figsize=(12, 4))
            axs[0].imshow(img_resized, cmap='gray')
            axs[0].set_title("Resized")
            axs[0].axis('off')

            axs[1].imshow(img_denoised, cmap='gray')
            axs[1].set_title("Denoised")
            axs[1].axis('off')

            axs[2].imshow(img_normalized, cmap='gray')
            axs[2].set_title("Normalized")
            axs[2].axis('off')

            plt.suptitle(f"{scanner} ‚Üí {dpi}\n{fname}", fontsize=10)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    preprocess_summary[scanner] = dpi_summary

print("\nüìä Preprocessing Summary for Official Folder:")
for scanner, dpi_data in preprocess_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Define base path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
feature_summary = {}

# üßº Preprocessing + Feature Extraction
def extract_features(img_gray):
    # Resize
    img_resized = cv2.resize(img_gray, (512, 512))

    # Denoise
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)

    # Normalize
    img_normalized = img_denoised.astype(np.float32) / 255.0

    # High-pass filter
    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])
    high_pass = cv2.filter2D(img_normalized, -1, kernel)

    # Wavelet decomposition
    coeffs2 = pywt.dwt2(img_normalized, 'db1')  # Daubechies 1
    approx, (horiz, vert, diag) = coeffs2

    return high_pass, approx, horiz, vert, diag

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for i, fname in enumerate(tif_files):
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            # Extract features
            hp, approx, horiz, vert, diag = extract_features(img_gray)
            valid_count += 1

            # Show preview for first image only
            if i == 0:
                titles = ["High-Pass", "Approximation", "Horizontal", "Vertical", "Diagonal"]
                images = [hp, approx, horiz, vert, diag]
                fig, axs = plt.subplots(1, 5, figsize=(20, 4))
                for j in range(5):
                    axs[j].imshow(images[j], cmap='gray')
                    axs[j].set_title(titles[j])
                    axs[j].axis('off')
                plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
                plt.tight_layout()
                plt.show()

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä Feature Extraction Summary:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

# üìÅ Base path
official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
feature_summary = {}

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        valid_count = 0

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            # Convert to grayscale if needed
            if len(img.shape) == 3:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                img_gray = img

            # Preprocess
            img_pre = preprocess_image(img_gray)

            # Extract features
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # Visualize
            fig, axs = plt.subplots(1, 3, figsize=(15, 4))
            axs[0].imshow(img_pre, cmap='gray')
            axs[0].set_title("Preprocessed")

            axs[1].imshow(fft_img, cmap='gray')
            axs[1].set_title("FFT Spectrum")

            axs[2].imshow(prnu_img, cmap='gray')
            axs[2].set_title("PRNU Residual")

            plt.suptitle(f"{scanner} ‚Üí {dpi} ‚Üí {fname}", fontsize=12)
            plt.tight_layout()
            plt.show()

            valid_count += 1

        dpi_summary[dpi] = valid_count
    feature_summary[scanner] = dpi_summary

print("\nüìä FFT + PRNU Feature Extraction Summary:")
for scanner, dpi_data in feature_summary.items():
    for dpi, count in dpi_data.items():
        print(f"{scanner} ‚Üí {dpi}: {count} images processed")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

official_path = "/content/drive/MyDrive/InfosysVirtual/Official"
image_counts = {}
histograms = []

# üîÅ Traverse folders
for scanner in sorted(os.listdir(official_path)):
    scanner_path = os.path.join(official_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    dpi_summary = {}
    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]
        dpi_summary[dpi] = len(tif_files)

        for fname in tif_files[:2]:  # Limit to first 2 for histogram preview
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            img_resized = cv2.resize(img, (512, 512))
            hist = cv2.calcHist([img_resized], [0], None, [256], [0, 256])
            histograms.append((f"{scanner} ‚Üí {dpi} ‚Üí {fname}", hist))

    image_counts[scanner] = dpi_summary

# Show histograms
for label, hist in histograms:
    plt.figure(figsize=(6, 3))
    plt.plot(hist, color='gray')
    plt.title(f"Histogram: {label}", fontsize=10)
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.tight_layout()
    plt.show()

# Flatten counts for bar graph
labels = []
counts = []

for scanner, dpi_data in image_counts.items():
    for dpi, count in dpi_data.items():
        labels.append(f"{scanner}\n{dpi}")
        counts.append(count)

plt.figure(figsize=(12, 6))
plt.bar(labels, counts, color='skyblue')
plt.xticks(rotation=45, ha='right')
plt.ylabel("Number of Images")
plt.title("üìä Image Count per Scanner/DPI Folder")
plt.tight_layout()
plt.show()

import os
import cv2
import numpy as np
import pywt
import matplotlib.pyplot as plt

from PIL import Image

# üìÅ Input and output paths
input_path = "/content/drive/MyDrive/InfosysVirtual/Official"
output_base = "/content/drive/MyDrive/InfosysVirtual/Official_Features"

# üßº Preprocessing
def preprocess_image(img):
    img_resized = cv2.resize(img, (512, 512))
    img_denoised = cv2.GaussianBlur(img_resized, (5, 5), 0)
    img_normalized = img_denoised.astype(np.float32) / 255.0
    return img_normalized

# üîç FFT extraction
def extract_fft(img):
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-8)
    return magnitude_spectrum

# üîç PRNU extraction
def extract_prnu(img):
    coeffs = pywt.dwt2(img, 'db1')
    cA, (cH, cV, cD) = coeffs
    content = pywt.idwt2((cA, (cH, cV, cD)), 'db1')
    noise = img - content
    prnu = noise / (img + 1e-8)
    return prnu

# üì¶ Save image as PNG
def save_image(array, path):
    array = np.clip(array * 255, 0, 255).astype(np.uint8)
    Image.fromarray(array).save(path)

# üîÅ Traverse folders
for scanner in sorted(os.listdir(input_path)):
    scanner_path = os.path.join(input_path, scanner)
    if not os.path.isdir(scanner_path):
        continue

    for dpi in sorted(os.listdir(scanner_path)):
        dpi_path = os.path.join(scanner_path, dpi)
        if not os.path.isdir(dpi_path):
            continue

        tif_files = [f for f in os.listdir(dpi_path) if f.lower().endswith(('.tif', '.tiff'))]

        for fname in tif_files:
            img_path = os.path.join(dpi_path, fname)
            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
            if img is None:
                print(f"‚ö†Ô∏è Skipped unreadable: {img_path}")
                continue

            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
            img_pre = preprocess_image(img_gray)
            fft_img = extract_fft(img_pre)
            prnu_img = extract_prnu(img_pre)

            # üìÅ Create output folder
            save_folder = os.path.join(output_base, scanner, dpi)
            os.makedirs(save_folder, exist_ok=True)

            # üßæ Save images
            base_name = os.path.splitext(fname)[0]
            save_image(img_pre, os.path.join(save_folder, f"{base_name}_preprocessed.png"))
            save_image(fft_img / np.max(fft_img), os.path.join(save_folder, f"{base_name}_fft.png"))
            save_image(prnu_img / np.max(np.abs(prnu_img)), os.path.join(save_folder, f"{base_name}_prnu.png"))

            print(f"‚úÖ Saved: {scanner}/{dpi}/{fname}")

import os
import glob
import pandas as pd

root_path = "/content/drive/MyDrive/InfosysVirtual/Official_Features"
lbp_features = []
labels = []
scanner_counts = {}

def extract_lbp(image_path):
    import cv2
    import numpy as np
    from skimage.feature import local_binary_pattern

    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        return None

    radius = 1
    n_points = 8 * radius
    lbp = local_binary_pattern(image, n_points, radius, method="uniform")
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))
    hist = hist.astype("float")
    hist /= (hist.sum() + 1e-6)
    return hist

for scanner_model in os.listdir(root_path):
    model_path = os.path.join(root_path, scanner_model)
    if not os.path.isdir(model_path):
        continue

    count = 0
    for sample_folder in os.listdir(model_path):
        sample_path = os.path.join(model_path, sample_folder)
        if not os.path.isdir(sample_path):
            continue

        image_candidates = glob.glob(os.path.join(sample_path, "*_preprocessed.png"))
        if not image_candidates:
            print("‚ùå No LBP image found in:", sample_path)
            continue

        image_path = image_candidates[0]
        print("‚úÖ Using:", image_path)

        features = extract_lbp(image_path)
        if features is None:
            print("‚ö†Ô∏è LBP failed for:", image_path)
            continue

        lbp_features.append(features)
        labels.append(scanner_model)
        count += 1

    scanner_counts[scanner_model] = count

# Convert to DataFrame
df_lbp = pd.DataFrame(lbp_features)
df_lbp["label"] = labels

# Summary table
summary_df = pd.DataFrame.from_dict(scanner_counts, orient="index", columns=["Samples"])
print("\nüìä Sample Count per Scanner Model:")
print(summary_df)

# Preview extracted features
print("\nüîç LBP Feature DataFrame Preview:")
print(df_lbp.head())

from google.colab import drive
drive.mount('/content/drive')

official_base = '/content/drive/MyDrive/InfosysVirtual/Official'

# === Imports ===
import os, cv2, numpy as np, pandas as pd
from PIL import Image
from tqdm import tqdm
from skimage.feature import local_binary_pattern
from scipy.fftpack import fft2
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb
from sklearn.linear_model import LogisticRegression
import torch
import torchvision.models as models
import torchvision.transforms as transforms

# === Feature extraction ===
def extract_handcrafted(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if img is None: return None
    img = cv2.resize(img, (128, 128))
    lbp = local_binary_pattern(img, P=8, R=1, method='uniform')
    lbp_hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59))
    fft = np.abs(fft2(img))
    fft_mean, fft_std = np.mean(fft), np.std(fft)
    energy = np.sum(img ** 2)
    return np.concatenate([lbp_hist, [fft_mean, fft_std, energy]])

resnet = models.resnet18(pretrained=True)
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Build dataset ===
features_hc, features_cnn, labels = [], [], []
label_map, label_counter = {}, 0

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    hc = extract_handcrafted(path)
                    cnn = extract_cnn(path)
                    if hc is not None and cnn is not None:
                        features_hc.append(hc)
                        features_cnn.append(cnn)
                        labels.append(label_map[key])

X_hc = np.array(features_hc)
X_cnn = np.array(features_cnn)
y = np.array(labels)

# === K-Fold setup ===
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
meta_preds, meta_labels = [], []

for fold, (train_idx, val_idx) in enumerate(kf.split(X_hc, y)):
    print(f"\nüìÅ Fold {fold+1}")

    X_train_hc, X_val_hc = X_hc[train_idx], X_hc[val_idx]
    X_train_cnn, X_val_cnn = X_cnn[train_idx], X_cnn[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]

    # Train base models
    svm = SVC(probability=True).fit(X_train_hc, y_train)
    rf = RandomForestClassifier().fit(X_train_hc, y_train)
    xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss').fit(X_train_hc, y_train)
    lgb_model = lgb.LGBMClassifier().fit(X_train_hc, y_train)
    cnn_clf = LogisticRegression(max_iter=1000).fit(X_train_cnn, y_train)

    # Validation predictions
    svm_val = svm.predict_proba(X_val_hc)
    rf_val = rf.predict_proba(X_val_hc)
    xgb_val = xgb_model.predict_proba(X_val_hc)
    lgb_val = lgb_model.predict_proba(X_val_hc)

    stacked_val = np.hstack([svm_val, rf_val, xgb_val, lgb_val, X_val_cnn])
    meta_preds.append(stacked_val)
    meta_labels.append(y_val)

# === Train final meta-model ===
X_meta = np.vstack(meta_preds)
y_meta = np.hstack(meta_labels)
meta_model = LogisticRegression(max_iter=1000)
meta_model.fit(X_meta, y_meta)

final_preds = meta_model.predict(X_meta)
acc = accuracy_score(y_meta, final_preds)
print(f"\n‚úÖ K-Fold Ensemble Accuracy: {acc:.2%}")

# === Imports ===
import os, numpy as np
from PIL import Image
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torchvision.models as models
import torchvision.transforms as transforms

# === Step 1: CNN feature extractor ===
resnet = models.resnet18(pretrained=True)
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Step 2: Build dataset ===
features_cnn, labels = [], []
label_map, label_counter = {}, 0

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        features_cnn.append(cnn)
                        labels.append(label_map[key])

X_cnn = np.array(features_cnn)
y = np.array(labels)

# === Step 3: Train CNN classifier ===
clf = LogisticRegression(max_iter=1000)
clf.fit(X_cnn, y)

# === Step 4: Accuracy ===
acc = accuracy_score(y, clf.predict(X_cnn))
print(f"\n‚úÖ CNN (ResNet18) Training Accuracy: {acc:.2%}")

# === Step 5: Confusion Matrix ===
cm = confusion_matrix(y, clf.predict(X_cnn))
xticks = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]
sns.heatmap(cm, annot=True, fmt='d', xticklabels=xticks, yticklabels=xticks, cmap='Blues')
plt.title("CNN (ResNet18) Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

from collections import defaultdict

# === Step: Map folder to predictions ===
folder_accuracy = defaultdict(lambda: {'correct': 0, 'total': 0})

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        pred = clf.predict(cnn.reshape(1, -1))[0]
                        actual = label_map[f"{source}_{model}"]
                        folder_key = f"{source}_{model}_{res}"
                        folder_accuracy[folder_key]['total'] += 1
                        if pred == actual:
                            folder_accuracy[folder_key]['correct'] += 1

# === Step: Print folder-wise accuracy ===
print("\nüìÇ Folder-wise Accuracy:")
for folder, stats in sorted(folder_accuracy.items()):
    correct = stats['correct']
    total = stats['total']
    acc = correct / total if total > 0 else 0
    print(f"{folder}: {acc:.2%} ({correct}/{total})")

# === Imports ===
import os, numpy as np
from PIL import Image
from collections import Counter
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import cv2

# === Step 1: CNN Feature Extractor ===
resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

def extract_cnn(path):
    try:
        img = Image.open(path).convert('RGB')
        tensor = transform(img).unsqueeze(0)
        with torch.no_grad():
            feat = resnet(tensor)
        return feat.squeeze().numpy()
    except:
        return None

# === Step 2: Build Dataset from Official + Wikipedia ===
features_cnn, labels = [], []
label_map, label_counter = {}, 0
sample_image_path = None  # For Grad-CAM

for source in ['Official', 'Wikipedia']:
    base = f'/content/drive/MyDrive/InfosysVirtual/{source}_Features'
    for model in sorted(os.listdir(base)):
        key = f"{source}_{model}"
        label_map[key] = label_counter
        label_counter += 1
        for res in ['150', '300']:
            folder = os.path.join(base, model, res)
            if not os.path.exists(folder): continue
            for file in os.listdir(folder):
                if file.endswith('_prnu.png'):
                    path = os.path.join(folder, file)
                    cnn = extract_cnn(path)
                    if cnn is not None:
                        features_cnn.append(cnn)
                        labels.append(label_map[key])
                        if sample_image_path is None:
                            sample_image_path = path  # First valid image for Grad-CAM

X_cnn = np.array(features_cnn)
y = np.array(labels)

# === Step 3: Train Logistic Regression Classifier ===
clf = LogisticRegression(max_iter=1000)
clf.fit(X_cnn, y)

# === Step 4: Training Accuracy ===
y_pred = clf.predict(X_cnn)
acc = accuracy_score(y, y_pred)
print(f"\n‚úÖ CNN (ResNet18) Training Accuracy: {acc:.2%}")

# === Step 5: PRNU File Counts per Scanner ===
scanner_counts = Counter(labels)
print("\nüìÅ Total PRNU Files per Scanner:")
for key, idx in sorted(label_map.items(), key=lambda x: x[1]):
    print(f"{key}: {scanner_counts[idx]} files")

# === Step 6: Confusion Matrix ===
cm = confusion_matrix(y, y_pred)
xticks = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]
sns.heatmap(cm, annot=True, fmt='d', xticklabels=xticks, yticklabels=xticks, cmap='Blues')
plt.title("CNN (ResNet18) Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# === Step 7: Classification Report ===
print("\nüìä Precision, Recall, F1-score:")
print(classification_report(y, y_pred, target_names=xticks, digits=2))

# === Step 8: Grad-CAM Visualization ===
gradients = []
activations = []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

# Load and preprocess image
img = Image.open(sample_image_path).convert('RGB')
rgb_image = np.array(img) / 255.0
tensor = transform(img).unsqueeze(0)

# Forward + backward pass
resnet.zero_grad()
output = resnet(tensor)
output[0].mean().backward()

# Grad-CAM computation
grad = gradients[0].squeeze().detach().numpy()
act = activations[0].squeeze().detach().numpy()
weights = np.mean(grad, axis=(1, 2))
cam = np.zeros(act.shape[1:], dtype=np.float32)
for i, w in enumerate(weights):
    cam += w * act[i]

cam = np.maximum(cam, 0)
cam = cv2.resize(cam, (rgb_image.shape[1], rgb_image.shape[0]))
cam = cam / cam.max()

# Overlay heatmap
heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
overlay = np.uint8(255 * rgb_image)
combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

# Display original and Grad-CAM
fig, axs = plt.subplots(1, 2, figsize=(10, 5))
axs[0].imshow(rgb_image)
axs[0].set_title("Original PRNU Image")
axs[0].axis('off')

axs[1].imshow(combined[:, :, ::-1])
axs[1].set_title("Grad-CAM Overlay")
axs[1].axis('off')
plt.tight_layout()
plt.show()

import joblib
import os

# Create models directory if it doesn't exist
model_dir = '/content/drive/MyDrive/InfosysVirtual/models'
os.makedirs(model_dir, exist_ok=True)

# Save trained classifier
joblib.dump(clf, os.path.join(model_dir, 'logreg_cnn.pkl'))

# Save label map
joblib.dump(label_map, os.path.join(model_dir, 'label_map.pkl'))

print("‚úÖ Model and label map saved successfully.")

import gradio as gr
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import joblib
import cv2

# === Load ResNet18 Feature Extractor ===
resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

# === Load Classifier and Label Map ===
clf = joblib.load('/content/drive/MyDrive/InfosysVirtual/models/logreg_cnn.pkl')
label_map = joblib.load('/content/drive/MyDrive/InfosysVirtual/models/label_map.pkl')
inv_label_map = {v: k for k, v in label_map.items()}

# === Grad-CAM Setup ===
gradients = []
activations = []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

# === Prediction Function ===
def predict_scanner(image):
    img = image.convert("RGB")
    tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        features = resnet(tensor).squeeze().numpy()

    pred = clf.predict([features])[0]
    proba = clf.predict_proba([features])[0][pred]
    label = inv_label_map[pred]

    # Grad-CAM
    resnet.zero_grad()
    output = resnet(tensor)
    output[0].mean().backward()

    grad = gradients[0].squeeze().detach().numpy()
    act = activations[0].squeeze().detach().numpy()
    weights = np.mean(grad, axis=(1, 2))
    cam = np.zeros(act.shape[1:], dtype=np.float32)
    for i, w in enumerate(weights):
        cam += w * act[i]
    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (img.size[0], img.size[1]))
    cam = cam / cam.max()

    rgb_image = np.array(img) / 255.0
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    overlay = np.uint8(255 * rgb_image)
    combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

    return label, f"{proba:.2f}", combined[:, :, ::-1]

# === Custom Gradio Frontend ===
with gr.Blocks(css=".gradio-container {background-color: #f9f9f9; font-family: 'Segoe UI';}") as app:
    gr.Markdown("""
    <div style="text-align:center;">
        <h1 style="color:#2c3e50;">üß† Scanner Identifier</h1>
        <p style="font-size:18px;">Upload a PRNU image to identify the scanner model using CNN features + Logistic Regression</p>
    </div>
    """)

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="üì§ Upload PRNU Image")
            submit_btn = gr.Button("üîç Analyze")
        with gr.Column(scale=1):
            label_output = gr.Text(label="üìå Predicted Scanner")
            confidence_output = gr.Text(label="üìà Confidence Score")
            gradcam_output = gr.Image(label="üî• Grad-CAM Overlay")

    submit_btn.click(fn=predict_scanner, inputs=image_input, outputs=[label_output, confidence_output, gradcam_output])

app.launch()

app_code = '''
import gradio as gr
import numpy as np
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import joblib
import cv2

resnet = models.resnet18(weights='IMAGENET1K_V1')
resnet.fc = torch.nn.Identity()
resnet.eval()
transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])

clf = joblib.load("logreg_cnn.pkl")
label_map = joblib.load("label_map.pkl")
inv_label_map = {v: k for k, v in label_map.items()}

gradients, activations = [], []

def backward_hook(module, grad_input, grad_output):
    gradients.append(grad_output[0])

def forward_hook(module, input, output):
    activations.append(output)

target_layer = resnet.layer4[-1]
target_layer.register_forward_hook(forward_hook)
target_layer.register_backward_hook(backward_hook)

def predict_scanner(image):
    img = image.convert("RGB")
    tensor = transform(img).unsqueeze(0)

    with torch.no_grad():
        features = resnet(tensor).squeeze().numpy()

    pred = clf.predict([features])[0]
    proba = clf.predict_proba([features])[0][pred]
    label = inv_label_map[pred]

    resnet.zero_grad()
    output = resnet(tensor)
    output[0].mean().backward()

    grad = gradients[0].squeeze().detach().numpy()
    act = activations[0].squeeze().detach().numpy()
    weights = np.mean(grad, axis=(1, 2))
    cam = np.zeros(act.shape[1:], dtype=np.float32)
    for i, w in enumerate(weights):
        cam += w * act[i]
    cam = np.maximum(cam, 0)
    cam = cv2.resize(cam, (img.size[0], img.size[1]))
    cam = cam / cam.max()

    rgb_image = np.array(img) / 255.0
    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    overlay = np.uint8(255 * rgb_image)
    combined = cv2.addWeighted(overlay, 0.5, heatmap, 0.5, 0)

    return label, f"{proba:.2f}", combined[:, :, ::-1]

with gr.Blocks(css=".gradio-container {background-color: #f9f9f9; font-family: 'Segoe UI';}") as app:
    gr.Markdown("""
    <div style="text-align:center;">
        <h1 style="color:#2c3e50;">üß† Scanner Identifier</h1>
        <p style="font-size:18px;">Upload a PRNU image to identify the scanner model using CNN features + Logistic Regression</p>
    </div>
    """)

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="üì§ Upload PRNU Image")
            submit_btn = gr.Button("üîç Analyze")
        with gr.Column(scale=1):
            label_output = gr.Text(label="üìå Predicted Scanner")
            confidence_output = gr.Text(label="üìà Confidence Score")
            gradcam_output = gr.Image(label="üî• Grad-CAM Overlay")

    submit_btn.click(fn=predict_scanner, inputs=image_input, outputs=[label_output, confidence_output, gradcam_output])

app.launch()
'''
with open("app.py", "w") as f:
    f.write(app_code)

reqs = '''
gradio
torch
torchvision
scikit-learn
joblib
pillow
opencv-python
'''
with open("requirements.txt", "w") as f:
    f.write(reqs)

from google.colab import files
files.download("app.py")
files.download("requirements.txt")
files.download("/content/drive/MyDrive/InfosysVirtual/models/logreg_cnn.pkl")
files.download("/content/drive/MyDrive/InfosysVirtual/models/label_map.pkl")